import numpy as np
import visualization
from utils import valuation_function, generate_curves_algorithm2, precompute_outcomes


class Config:
    def __init__(self):
        self.M_TYPES = 10           # ä¹°å®¶ç±»å‹æ•°é‡
        self.N_ITEMS = 100          # æ•°æ®ç‚¹æ€»æ•°
        self.T_HORIZON = self.M_TYPES * 10000      # æ€»å›åˆæ•°
        
        # è‡ªåŠ¨ç”ŸæˆçœŸå®çš„ä¹°å®¶ç±»å‹åˆ†å¸ƒ
        self.Q_TRUE = self._generate_true_distribution(self.M_TYPES)
        
        self.J = 2.0                   # æ”¶ç›Šé€’å‡å¸¸æ•°
        self.epsilon = 0.1             # è¿‘ä¼¼ç²¾åº¦å‚æ•°
        self.num_samples = max(7, self.M_TYPES + 5)  # ç”Ÿæˆçš„ä»·æ ¼æ›²çº¿æ•°é‡
    
    def _generate_true_distribution(self, m_types):
        """
        è‡ªåŠ¨ç”ŸæˆçœŸå®çš„ä¹°å®¶ç±»å‹åˆ†å¸ƒ
        """
        if m_types == 1:
            return np.array([1.0])
        elif m_types == 2:
            return np.array([0.6, 0.4])
        elif m_types == 3:
            return np.array([0.6, 0.3, 0.1])
        elif m_types == 4:
            return np.array([0.5, 0.3, 0.15, 0.05])
        else:
            # å¯¹äºæ›´å¤šç±»å‹ï¼Œä½¿ç”¨é«˜æ–¯åˆ†å¸ƒ
            distribution = np.random.normal(loc=0.5, scale=0.1, size=m_types)
            distribution = np.abs(distribution)  # ç¡®ä¿æ‰€æœ‰å€¼ä¸ºæ­£
            distribution /= np.sum(distribution)  # å½’ä¸€åŒ–ä¸ºæ¦‚ç‡åˆ†å¸ƒ
            
            return distribution
    
    def print_config(self):
        """
        æ‰“å°é…ç½®ä¿¡æ¯
        """
        print(f"   å‚æ•°è®¾ç½®:")
        print(f"   ä¹°å®¶ç±»å‹æ•°é‡ (M_TYPES) = {self.M_TYPES}")
        print(f"   æ•°æ®ç‚¹æ€»æ•° (N_ITEMS) = {self.N_ITEMS}")
        print(f"   æ€»å›åˆæ•° (T_HORIZON) = {self.T_HORIZON}")
        print(f"   çœŸå®ä¹°å®¶åˆ†å¸ƒ (Q_TRUE) = {self.Q_TRUE}")
        print(f"   æ”¶ç›Šé€’å‡å¸¸æ•° (J) = {self.J}")
        print(f"   è¿‘ä¼¼ç²¾åº¦å‚æ•° (epsilon) = {self.epsilon}")
        print(f"   ç”Ÿæˆæ›²çº¿æ•°é‡ (num_samples) = {self.num_samples}")
        print()
        
        # éªŒè¯åˆ†å¸ƒæ˜¯å¦æœ‰æ•ˆ
        if abs(np.sum(self.Q_TRUE) - 1.0) > 1e-10:
            print("çœŸå®åˆ†å¸ƒæ¦‚ç‡å’Œä¸ç­‰äº1")
        else:
            print("çœŸå®åˆ†å¸ƒæœ‰æ•ˆ")

class UCBAgent:
    """
    å®ç°äº†è®ºæ–‡ä¸­ç®—æ³•3çš„UCBã€‚
    """
    def __init__(self, m_types: int, T_horizon: int, precomputed_revenues, precomputed_purchases):
        """
        åˆå§‹åŒ–Agentçš„çŠ¶æ€ã€‚
        
        å‚æ•°:
        - m_types: ä¹°å®¶ç±»å‹æ€»æ•° (m)
        - T_horizon: æ€»è½®æ•° (T)
        - precomputed_revenues: é¢„è®¡ç®—çš„æ”¶å…¥çŸ©é˜µ
        - precomputed_purchases: é¢„è®¡ç®—çš„è´­ä¹°é‡çŸ©é˜µ
        """
        self.m = m_types
        self.T = T_horizon
        self.revenues = precomputed_revenues
        self.purchases = precomputed_purchases
        self.num_curves = precomputed_revenues.shape[0]

        # Agentå†…éƒ¨çŠ¶æ€
        self.t = 1  # å½“å‰å›åˆæ•°ï¼Œä»1å¼€å§‹
        # T_{i,t}: ç±»å‹iè¢«"æ¢ç´¢"çš„æ¬¡æ•°
        self.T_i = np.zeros(m_types)
        # N_i: ç±»å‹iè¢«å®é™…è§‚å¯Ÿåˆ°çš„æ¬¡æ•°
        self.N_i = np.zeros(m_types)
        
        # ç”¨äºå¯è§†åŒ–çš„å†å²è®°å½•
        self.history = {
            'round': [],
            'action': [],
            'revenue': [],
            'cumulative_revenue': [],
            'buyer_type': [],
            'q_estimates': [],
            'confidence_bounds': [],
            'ucb_values': [],
            'T_i_history': [],
            'N_i_history': []
        }

    def choose_action(self) -> int:
        """
        æ ¹æ®UCBè§„åˆ™é€‰æ‹©ä¸€ä¸ªä»·æ ¼æ›²çº¿çš„ç´¢å¼•ã€‚
        """
        # ç®—æ³•è§„å®šï¼Œç¬¬ä¸€è½®å…è´¹ï¼Œä»¥ç¡®ä¿è·å¾—åé¦ˆ
        if self.t == 1:
            # ç¬¬ä¸€è½®ä¹Ÿéœ€è¦è®°å½•å€¼ï¼Œå³ä½¿æ˜¯åˆå§‹å€¼
            q_bar = np.zeros(self.m)
            confidence_bonus = np.zeros(self.m)
            rev_hat = np.zeros(self.num_curves)
            
            self.history['q_estimates'].append(q_bar.copy())
            self.history['confidence_bounds'].append(confidence_bonus.copy())
            self.history['ucb_values'].append(rev_hat.copy())
            
            return 0  # å‡è®¾ç´¢å¼•0æ˜¯å…¨é›¶ä»·æ ¼æ›²çº¿

        # 1. è®¡ç®—å¯¹qçš„ç»éªŒä¼°è®¡ q_bar
        #    ä¸ºé¿å…é™¤ä»¥0ï¼Œå½“T_iä¸º0æ—¶ï¼Œq_barä¹Ÿä¸º0
        T_i_safe = np.maximum(self.T_i, 1) # é˜²æ­¢é™¤é›¶
        q_bar = self.N_i / T_i_safe

        # 2. è®¡ç®—ç½®ä¿¡åº¦å¥–åŠ±é¡¹
        confidence_bonus = np.sqrt(np.log(self.T) / T_i_safe)

        # 3. æ„é€ ä¹è§‚çš„qä¼°è®¡ q_hat
        q_hat = q_bar + confidence_bonus

        # 4. è®¡ç®—æ¯ä¸ªä»·æ ¼æ›²çº¿çš„æœŸæœ›æ”¶å…¥çš„UCB (rev_hat)
        #    è¿™æ˜¯è®ºæ–‡å…¬å¼(7)çš„å®ç°
        #    rev_hat(p) = sum(q_hat_i * revenue(p, i)) for i in 1..m
        rev_hat = self.revenues @ q_hat  
        
        # è®°å½•UCBå€¼ç”¨äºå¯è§†åŒ–
        self.history['q_estimates'].append(q_bar.copy())
        self.history['confidence_bounds'].append(confidence_bonus.copy())
        self.history['ucb_values'].append(rev_hat.copy())
        
        # 5. é€‰æ‹©å…·æœ‰æœ€é«˜UCBæ”¶å…¥çš„æ›²çº¿
        chosen_curve_idx = np.argmax(rev_hat)
        return chosen_curve_idx

    def update(self, chosen_curve_idx: int, feedback_type: int or None):
        """
        æ ¹æ®ç¯å¢ƒåé¦ˆæ›´æ–°å†…éƒ¨çŠ¶æ€ã€‚
        
        å‚æ•°:
        - chosen_curve_idx: æœ¬è½®é€‰æ‹©çš„ä»·æ ¼æ›²çº¿çš„ç´¢å¼•
        - feedback_type: è§‚å¯Ÿåˆ°çš„ä¹°å®¶ç±»å‹ç´¢å¼•ï¼Œå¦‚æœæœªè´­ä¹°åˆ™ä¸ºNone
        """
        # 1. æ›´æ–°æ¢ç´¢æ¬¡æ•° T_i
        #    S_t æ˜¯æœ¬è½®ä»·æ ¼ä¸‹ä¼šè´­ä¹°çš„ä¹°å®¶ç±»å‹é›†åˆ
        #    å³èƒ½å¤Ÿå¸å¼•å“ªäº›ä¹°å®¶
        S_t = np.where(self.purchases[chosen_curve_idx, :] > 0)[0]
        self.T_i[S_t] += 1

        
        # 2. å¦‚æœæœ‰è´­ä¹°ï¼Œæ›´æ–°è§‚å¯Ÿæ¬¡æ•° N_i
        #   å³æ­¤è½®å‡ºç°çš„ä¹°å®¶åˆšå¥½åœ¨S_tä¸­ï¼Œå³ä¹°äº†ï¼Œé‚£ä¹ˆç»™å¯¹åº”ç±»å‹çš„N_iåŠ 1
        revenue_this_round = 0
        if feedback_type is not None:
            self.N_i[feedback_type] += 1
            revenue_this_round = self.revenues[chosen_curve_idx, feedback_type]
        
        # è®°å½•å†å²æ•°æ®
        self.history['round'].append(self.t)
        self.history['action'].append(chosen_curve_idx)
        self.history['revenue'].append(revenue_this_round)
        self.history['cumulative_revenue'].append(
            self.history['cumulative_revenue'][-1] + revenue_this_round if self.history['cumulative_revenue'] else revenue_this_round
        )
        self.history['buyer_type'].append(feedback_type)
        self.history['T_i_history'].append(self.T_i.copy())
        self.history['N_i_history'].append(self.N_i.copy())
            
        # è¿›å…¥ä¸‹ä¸€è½®
        self.t += 1

# ==============================================================================
# 3. ç»¼åˆè¿è¡Œå‡½æ•°
# ==============================================================================

def run_with_visualization(M_TYPES=3, N_ITEMS=100, T_HORIZON=5000, Q_TRUE=None,J=2.0,epsilon=0.1,num_samples=7):
    """
    è¿è¡ŒUCBç®—æ³•å¹¶ç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–
    """
    
    print("ğŸš€ å¼€å§‹UCBç®—æ³•å¯è§†åŒ–æ¼”ç¤º")
    print("=" * 50)
    
    print("\nğŸ“Š 1. å‡†å¤‡æ•°æ®...")
    price_curves = generate_curves_algorithm2(N_ITEMS, M_TYPES, J, epsilon, num_samples)
    revenues, purchases = precompute_outcomes(price_curves, M_TYPES, N_ITEMS)
    
    # 2. åˆå§‹åŒ–å¹¶è¿è¡ŒUCB Agent
    print("\nğŸ¤– 2. åˆå§‹åŒ–UCB Agent...")
    agent = UCBAgent(M_TYPES, T_HORIZON, revenues, purchases)
    
    print(f"\nğŸ¯ 3. å¼€å§‹æ¨¡æ‹Ÿè¿è¡Œ (T={T_HORIZON})...")
    total_revenue = 0
    
    # ç”¨äºè¿›åº¦æ˜¾ç¤º
    progress_points = [int(T_HORIZON * p) for p in [0.1, 0.25, 0.5, 0.75, 1.0]]
    progress_idx = 0
    
    for t in range(T_HORIZON):
        # æ˜¾ç¤ºè¿›åº¦
        if progress_idx < len(progress_points) and t >= progress_points[progress_idx]:
            print(f"è¿›åº¦: {int(100 * (progress_idx + 1) / len(progress_points))}% å®Œæˆ")
            progress_idx += 1
        
        # 1. Agenté€‰æ‹©åŠ¨ä½œ
        action_idx = agent.choose_action()
        
        # 2. ç¯å¢ƒç”Ÿæˆä¹°å®¶
        true_type = np.random.choice(M_TYPES, p=Q_TRUE)
        
        # 3. ç¡®å®šç»“æœ
        n_bought = purchases[action_idx, true_type]
        feedback = None
        
        if n_bought > 0:
            revenue_this_round = revenues[action_idx, true_type]
            total_revenue += revenue_this_round
            feedback = true_type
        
        # 4. æ›´æ–°Agent
        agent.update(action_idx, feedback)
    
    print(f"\nâœ… æ¨¡æ‹Ÿå®Œæˆ!")
    print(f"æ€»æ”¶å…¥: {total_revenue:.2f}")
    final_q_estimate = agent.N_i / np.maximum(agent.T_i, 1)
    
    estimation_error = np.abs(config.Q_TRUE - final_q_estimate)

    print(f"å­¦ä¹ åˆ°çš„ä¼°è®¡: {np.round(final_q_estimate, 3)}")
    print(f"ä¼°è®¡è¯¯å·®: {np.round(estimation_error, 3)}")
    print(f"å¹³å‡ç»å¯¹è¯¯å·®: {np.mean(estimation_error):.3f}")

    # å¯è§†åŒ–
    output_folder = None

    print("\n ç”Ÿæˆå¯è§†åŒ–...")
    output_folder = visualization.run_visualization_suite(
        M_TYPES, N_ITEMS, T_HORIZON, Q_TRUE, 
        price_curves, valuation_function, revenues, purchases, agent
    )

    return agent, output_folder

# ============================================================================================================================================================
if __name__ == '__main__':    
    config = Config()
    print(f"\n{'='*60}")
    print(f"æµ‹è¯•ä¹°å®¶ç±»å‹æ•°é‡: {config.M_TYPES}")
    print(f"{'='*60}")
    
    config.print_config()
    
    # è¿è¡Œå®Œæ•´çš„å¯è§†åŒ–æ¼”ç¤º
    agent, output_folder = run_with_visualization(
        config.M_TYPES, config.N_ITEMS, 
        config.T_HORIZON, config.Q_TRUE, 
        config.J, config.epsilon, config.num_samples)
    
    print("-" * 30)
    
    # è®¡ç®—regret
    best_curve_revenues = np.max(agent.revenues @ config.Q_TRUE)
    theoretical_best = best_curve_revenues * config.T_HORIZON
    actual_revenue = agent.history['cumulative_revenue'][-1]
    regret = theoretical_best - actual_revenue
    
    print(f"ç†è®ºæœ€ä¼˜å•è½®æ”¶å…¥: {best_curve_revenues:.3f}")
    print(f"ç†è®ºæœ€ä¼˜æ€»æ”¶å…¥: {theoretical_best:.2f}")
    print(f"å®é™…è·å¾—æ€»æ”¶å…¥: {actual_revenue:.2f}")
    print(f"æ€»regret: {regret:.2f}")
    print(f"å¹³å‡regret: {regret/config.T_HORIZON:.4f}")
    
    # æ˜¾ç¤ºæœ€ç»ˆçš„ä»·æ ¼æ›²çº¿åå¥½
    action_counts = np.bincount(agent.history['action'], minlength=agent.num_curves)
    best_action = np.argmax(action_counts)
    print(f"æœ€å¸¸é€‰æ‹©çš„ä»·æ ¼æ›²çº¿: æ›²çº¿{best_action} (é€‰æ‹©äº† {action_counts[best_action]} æ¬¡)")
    
    if output_folder is not None:
        print(f"ğŸ“‚ è¯·æŸ¥çœ‹ç”Ÿæˆçš„å›¾ç‰‡æ–‡ä»¶å¤¹: {output_folder}")
    
    print(f"\nâœ… æµ‹è¯•å®Œæˆ!")
